{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fancy_einsum import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[0, 3, 0, 2, 2],\n",
      "         [1, 1, 1, 3, 2],\n",
      "         [2, 1, 1, 1, 2],\n",
      "         [1, 0, 2, 3, 2]],\n",
      "\n",
      "        [[1, 1, 0, 0, 0],\n",
      "         [0, 1, 0, 2, 1],\n",
      "         [1, 2, 0, 2, 2],\n",
      "         [0, 3, 1, 0, 1]],\n",
      "\n",
      "        [[2, 1, 3, 0, 0],\n",
      "         [2, 2, 1, 0, 0],\n",
      "         [1, 1, 3, 0, 1],\n",
      "         [2, 0, 1, 1, 3]]])\n",
      "\n",
      "gate:\n",
      "tensor([[3, 1],\n",
      "        [0, 3],\n",
      "        [2, 3],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# n_experts = 2\n",
    "# topk (capacity eksperta) = 3\n",
    "# gate_dim = 4\n",
    "x = torch.randint(0, 4, (3, 4, 5)) # (batch, cutoff, dmodel)\n",
    "gate = torch.randint(0, 4, (4, 2)) # (cutoff, n_experts)\n",
    "print(f'x:\\n{x}\\n\\ngate:\\n{gate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_out:\n",
      "tensor([[[21,  7],\n",
      "         [ 0, 24],\n",
      "         [14, 21],\n",
      "         [ 8,  0]],\n",
      "\n",
      "        [[ 6,  2],\n",
      "         [ 0, 12],\n",
      "         [14, 21],\n",
      "         [ 5,  0]],\n",
      "\n",
      "        [[18,  6],\n",
      "         [ 0, 15],\n",
      "         [12, 18],\n",
      "         [ 7,  0]]])\n",
      "\n",
      " shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1. używamy gate, żeby stworzyć reprezentację ekspertów zamiast dmodel\n",
    "gate_out = einsum('batch cutoff dmodel, cutoff n_experts -> batch cutoff n_experts', x, gate)\n",
    "print(f'gate_out:\\n{gate_out}\\n\\n shape: {gate_out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[21,  0, 14,  8],\n",
       "         [ 6,  0, 14,  5],\n",
       "         [18,  0, 12,  7]],\n",
       "\n",
       "        [[ 7, 24, 21,  0],\n",
       "         [ 2, 12, 21,  0],\n",
       "         [ 6, 15, 18,  0]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wymiar eksperta chcę żeby był na początku\n",
    "gate_out = gate_out.permute(2, 0, 1)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21,  0, 14,  8,  6,  0, 14,  5, 18,  0, 12,  7],\n",
       "        [ 7, 24, 21,  0,  2, 12, 21,  0,  6, 15, 18,  0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spłaszczam wymiary 2 i 3, żeby każdy ekspert wybrał sobie swobodnie tokeny (ogólnie tokenów w batchu jest 12)\n",
    "gate_out = gate_out.flatten(start_dim=1)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gate_out float tensor\n",
    "gate_out = gate_out.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz przeprowadzamy softmax po 1 wymiarze\n",
    "gate_out = gate_out.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5081e-01, 7.2096e-10, 8.6702e-04, 2.1491e-06, 2.9085e-07, 7.2096e-10,\n",
       "         8.6702e-04, 1.0700e-07, 4.7338e-02, 7.2096e-10, 1.1734e-04, 7.9062e-07],\n",
       "        [3.7561e-08, 9.0729e-01, 4.5171e-02, 3.4251e-11, 2.5309e-10, 5.5746e-06,\n",
       "         4.5171e-02, 3.4251e-11, 1.3818e-08, 1.1197e-04, 2.2489e-03, 3.4251e-11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  8,  6,  2, 10,  3, 11],\n",
       "        [ 1,  6,  2, 10,  9,  5,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_gate_out = gate_out\n",
    "# wybierz topk tokenów dla każdego eksperta\n",
    "gate_out = torch.topk(gate_out, k=TOPK, dim=1).indices\n",
    "\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of softmax gate out: torch.Size([2, 12]), shape of x: torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of softmax gate out: {softmax_gate_out.shape}, shape of x: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_out = gate_out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.flatten(start_dim=0, end_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of softmax gate out: torch.Size([2, 12]), shape of x: torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of softmax gate out: {softmax_gate_out.shape}, shape of x: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.5081e-01, 4.7338e-02, 8.6702e-04, 8.6702e-04, 1.1734e-04, 2.1491e-06,\n",
       "         7.9062e-07, 7.2096e-10, 8.6702e-04, 8.6702e-04, 1.1734e-04, 7.2096e-10,\n",
       "         7.2096e-10, 9.5081e-01],\n",
       "        [3.7561e-08, 1.3818e-08, 4.5171e-02, 4.5171e-02, 2.2489e-03, 3.4251e-11,\n",
       "         3.4251e-11, 9.0729e-01, 4.5171e-02, 4.5171e-02, 2.2489e-03, 1.1197e-04,\n",
       "         5.5746e-06, 3.7561e-08]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(softmax_gate_out, dim=1, index=gate_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_out = gate_out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  8,  6,  2, 10,  3, 11],\n",
       "        [ 1,  6,  2, 10,  9,  5,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 3, 0, 2, 2],\n",
       "         [1, 1, 1, 3, 2],\n",
       "         [2, 1, 1, 1, 2],\n",
       "         [1, 0, 2, 3, 2]],\n",
       "\n",
       "        [[1, 1, 0, 0, 0],\n",
       "         [0, 1, 0, 2, 1],\n",
       "         [1, 2, 0, 2, 2],\n",
       "         [0, 3, 1, 0, 1]],\n",
       "\n",
       "        [[2, 1, 3, 0, 0],\n",
       "         [2, 2, 1, 0, 0],\n",
       "         [1, 1, 3, 0, 1],\n",
       "         [2, 0, 1, 1, 3]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 3, 2, 2],\n",
       "        [2, 0, 1, 2, 3],\n",
       "        [2, 0, 3, 0, 2],\n",
       "        [3, 3, 0, 1, 0],\n",
       "        [0, 3, 1, 0, 1],\n",
       "        [0, 2, 0, 1, 0],\n",
       "        [3, 3, 1, 1, 1],\n",
       "        [3, 2, 3, 2, 2],\n",
       "        [3, 3, 1, 1, 1],\n",
       "        [1, 3, 2, 2, 0],\n",
       "        [3, 2, 1, 1, 1],\n",
       "        [1, 0, 2, 3, 0],\n",
       "        [0, 2, 2, 0, 2],\n",
       "        [0, 3, 1, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(x, dim=0, index=gate_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2, 2, 0],\n",
       "        [0, 2, 0, 1, 0],\n",
       "        [3, 3, 0, 1, 0],\n",
       "        [3, 3, 1, 1, 1],\n",
       "        [1, 0, 2, 3, 0],\n",
       "        [0, 3, 1, 0, 1],\n",
       "        [2, 0, 1, 2, 3],\n",
       "        [1, 0, 0, 2, 0],\n",
       "        [3, 2, 1, 1, 1],\n",
       "        [3, 2, 3, 2, 2],\n",
       "        [2, 0, 3, 0, 2],\n",
       "        [0, 2, 2, 0, 2]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0],\n",
       "        [ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5],\n",
       "        [ 6],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [11]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  8,  6,  2, 10,  3, 11,  1,  6,  2, 10,  9,  5,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1,  2,  2,  3,  5,  6,  6,  8,  9, 10, 10, 11])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(gate_out.unsqueeze(0) == torch.arange(12).unsqueeze(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False,  True, False, False,\n",
       "         False, False, False, False],\n",
       "        [False, False, False,  True, False, False, False, False, False,  True,\n",
       "         False, False, False, False],\n",
       "        [False, False, False, False, False,  True, False, False, False, False,\n",
       "         False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False],\n",
       "        [False, False,  True, False, False, False, False, False,  True, False,\n",
       "         False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False,  True, False, False],\n",
       "        [False, False, False, False,  True, False, False, False, False, False,\n",
       "          True, False, False, False],\n",
       "        [False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.unsqueeze(0) == torch.arange(12).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zakoduj wybór eksperta jako one hot\n",
    "# tutaj dodać i odjąć odpowiedni softmax (można jakoś pomnożyć przez one te softmaxy i wtedy dodać i odjąć takie zwierzę)\n",
    "gate_out = torch.nn.functional.one_hot(gate_out, num_classes=12)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate out shape: torch.Size([2, 7, 12]), softmax_gate_out shape: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "print(f'Gate out shape: {gate_out.shape}, softmax_gate_out shape: {softmax_gate_out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          9.0924e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1221e-04,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.1221e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.3848e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          8.5083e-14, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 9.0931e-01, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          4.5272e-02, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 4.5272e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1222e-04, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5187e-05,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.5187e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3849e-08,\n",
       "          0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_mask = einsum('n_experts topk n_examples, n_experts n_examples -> n_experts topk n_examples', gate_out, softmax_gate_out)\n",
    "softmax_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate out: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 1.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 1.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 1.0000, 0.0000, 0.0000]]]) \n",
      "\n",
      " softmax_mask: tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          9.0924e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1221e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.1221e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 1.3848e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          8.5083e-14, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 9.0931e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          4.5272e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 4.5272e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1222e-04, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5187e-05,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.5187e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3849e-08,\n",
      "          0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "gate_out = gate_out + softmax_mask - softmax_mask\n",
    "print(f'Gate out: {gate_out} \\n\\n softmax_mask: {softmax_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_out:\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
      "\n",
      " shape: torch.Size([14, 12])\n"
     ]
    }
   ],
   "source": [
    "gate_out_flattened = gate_out.flatten(start_dim=0, end_dim=1)\n",
    "print(f'gate_out:\\n{gate_out_flattened}\\n\\n shape: {gate_out_flattened.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = torch.eye(12)\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_examples:\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "\n",
      " shape: torch.Size([14, 12])\n"
     ]
    }
   ],
   "source": [
    "chosen_examples = einsum('n_elems n_elems, expert_layer_width n_elems -> expert_layer_width n_elems', id, gate_out_flattened)\n",
    "print(f'chosen_examples:\\n{chosen_examples}\\n\\n shape: {chosen_examples.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_chosen_examples = (chosen_examples.sum(dim=0) == 0).float()\n",
    "not_chosen_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 12])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z powrotem odwróć spłaszczenie\n",
    "# gate_out = gate_out.view(2, TOPK, 3, 4)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=3, cutoff=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0, 3, 3],\n",
       "         [3, 2, 3, 0, 1],\n",
       "         [3, 1, 1, 0, 0],\n",
       "         [0, 2, 2, 1, 1]],\n",
       "\n",
       "        [[1, 3, 1, 2, 1],\n",
       "         [1, 1, 1, 3, 0],\n",
       "         [1, 3, 3, 1, 3],\n",
       "         [1, 1, 2, 1, 3]],\n",
       "\n",
       "        [[3, 0, 3, 0, 1],\n",
       "         [0, 1, 1, 0, 3],\n",
       "         [1, 3, 1, 0, 3],\n",
       "         [2, 1, 0, 2, 3]]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2, 2, 0],\n",
       "        [0, 2, 0, 1, 0],\n",
       "        [3, 3, 0, 1, 0],\n",
       "        [3, 3, 1, 1, 1],\n",
       "        [1, 0, 2, 3, 0],\n",
       "        [0, 3, 1, 0, 1],\n",
       "        [2, 0, 1, 2, 3],\n",
       "        [1, 0, 0, 2, 0],\n",
       "        [3, 2, 1, 1, 1],\n",
       "        [3, 2, 3, 2, 2],\n",
       "        [2, 0, 3, 0, 2],\n",
       "        [0, 2, 2, 0, 2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.flatten(start_dim=0, end_dim=1)\n",
    "x\n",
    "# tu zapisać x przed wejściem do layera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_before_experts = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[1, 3, 1, 2, 1],\n",
      "         [0, 1, 0, 3, 3],\n",
      "         [3, 0, 3, 0, 1],\n",
      "         [1, 1, 2, 1, 3],\n",
      "         [2, 1, 0, 2, 3],\n",
      "         [0, 2, 2, 1, 1],\n",
      "         [3, 2, 3, 0, 1]],\n",
      "\n",
      "        [[3, 2, 3, 0, 1],\n",
      "         [1, 1, 1, 3, 0],\n",
      "         [0, 1, 1, 0, 3],\n",
      "         [2, 1, 0, 2, 3],\n",
      "         [1, 1, 2, 1, 3],\n",
      "         [0, 2, 2, 1, 1],\n",
      "         [1, 3, 1, 0, 3]]])\n",
      "\n",
      " shape: torch.Size([2, 7, 5])\n"
     ]
    }
   ],
   "source": [
    "# teraz permutujemy macierz x zgodne z tym one hot\n",
    "x = einsum('n_elems dmodel, n_experts topk n_elems -> n_experts topk dmodel', x, gate_out)\n",
    "print(f'x:\\n{x}\\n\\n shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[1, 3, 1, 2, 1],\n",
      "        [0, 1, 0, 3, 3],\n",
      "        [3, 0, 3, 0, 1],\n",
      "        [1, 1, 2, 1, 3],\n",
      "        [2, 1, 0, 2, 3],\n",
      "        [0, 2, 2, 1, 1],\n",
      "        [3, 2, 3, 0, 1],\n",
      "        [3, 2, 3, 0, 1],\n",
      "        [1, 1, 1, 3, 0],\n",
      "        [0, 1, 1, 0, 3],\n",
      "        [2, 1, 0, 2, 3],\n",
      "        [1, 1, 2, 1, 3],\n",
      "        [0, 2, 2, 1, 1],\n",
      "        [1, 3, 1, 0, 3]])\n",
      "\n",
      " shape: torch.Size([14, 5])\n"
     ]
    }
   ],
   "source": [
    "# wypłasczamy wymiar 0 i 1, tak żeby otrzymać macierz wejścia do warstwy ekspertóœ\n",
    "x = x.flatten(start_dim=0, end_dim=1)\n",
    "print(f'x:\\n{x}\\n\\n shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 12])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dodajemy do siebie wyniki dla tych tokenów, które były wybrane przez wielu ekspertów\n",
    "# upewnić się, czy odpermutowuję tu poprawnie\n",
    "chosen_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[0., 1., 0., 3., 3.],\n",
      "        [6., 4., 6., 0., 2.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 4., 4., 2., 2.],\n",
      "        [1., 3., 1., 2., 1.],\n",
      "        [1., 1., 1., 3., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [2., 2., 4., 2., 6.],\n",
      "        [3., 0., 3., 0., 1.],\n",
      "        [0., 1., 1., 0., 3.],\n",
      "        [1., 3., 1., 0., 3.],\n",
      "        [4., 2., 0., 4., 6.]])\n",
      "\n",
      " shape: torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "summed = einsum('expert_layer_width n_elems, expert_layer_width dmodel -> n_elems dmodel', chosen_examples.float(), x.float())\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [3., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 3., 3., 1., 3.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add examples that were not chosen by any expert\n",
    "einsum('n_elems dmodel, n_elems -> n_elems dmodel', x_before_experts, not_chosen_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[0., 1., 0., 3., 3.],\n",
      "        [6., 4., 6., 0., 2.],\n",
      "        [3., 1., 1., 0., 0.],\n",
      "        [0., 4., 4., 2., 2.],\n",
      "        [1., 3., 1., 2., 1.],\n",
      "        [1., 1., 1., 3., 0.],\n",
      "        [1., 3., 3., 1., 3.],\n",
      "        [2., 2., 4., 2., 6.],\n",
      "        [3., 0., 3., 0., 1.],\n",
      "        [0., 1., 1., 0., 3.],\n",
      "        [1., 3., 1., 0., 3.],\n",
      "        [4., 2., 0., 4., 6.]])\n",
      "\n",
      " shape: torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "summed += einsum('n_elems dmodel, n_elems -> n_elems dmodel', x_before_experts, not_chosen_examples)\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[[0., 1., 0., 3., 3.],\n",
      "         [6., 4., 6., 0., 2.],\n",
      "         [3., 1., 1., 0., 0.],\n",
      "         [0., 4., 4., 2., 2.]],\n",
      "\n",
      "        [[1., 3., 1., 2., 1.],\n",
      "         [1., 1., 1., 3., 0.],\n",
      "         [1., 3., 3., 1., 3.],\n",
      "         [2., 2., 4., 2., 6.]],\n",
      "\n",
      "        [[3., 0., 3., 0., 1.],\n",
      "         [0., 1., 1., 0., 3.],\n",
      "         [1., 3., 1., 0., 3.],\n",
      "         [4., 2., 0., 4., 6.]]])\n",
      "\n",
      " shape: torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# again reshape summed to original shape with batch and cutoff\n",
    "summed = summed.view(3, 4, 5)\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
