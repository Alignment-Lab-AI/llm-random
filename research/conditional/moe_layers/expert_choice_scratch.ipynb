{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fancy_einsum import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[2, 0, 3, 1, 1],\n",
      "         [0, 0, 1, 1, 2],\n",
      "         [1, 1, 1, 2, 1],\n",
      "         [3, 2, 0, 3, 0]],\n",
      "\n",
      "        [[2, 3, 0, 1, 1],\n",
      "         [3, 2, 2, 0, 3],\n",
      "         [0, 0, 2, 3, 0],\n",
      "         [0, 0, 0, 2, 0]],\n",
      "\n",
      "        [[2, 3, 1, 0, 3],\n",
      "         [0, 3, 3, 3, 0],\n",
      "         [2, 1, 1, 1, 0],\n",
      "         [2, 0, 1, 2, 1]]])\n",
      "\n",
      "gate:\n",
      "tensor([[3, 1],\n",
      "        [3, 0],\n",
      "        [0, 3],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# n_experts = 2\n",
    "# topk (capacity eksperta) = 3\n",
    "# gate_dim = 4\n",
    "x = torch.randint(0, 4, (3, 4, 5)) # (batch, cutoff, dmodel)\n",
    "gate = torch.randint(0, 4, (4, 2)) # (cutoff, n_experts)\n",
    "print(f'x:\\n{x}\\n\\ngate:\\n{gate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_out:\n",
      "tensor([[[21,  7],\n",
      "         [12,  0],\n",
      "         [ 0, 18],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[21,  7],\n",
      "         [30,  0],\n",
      "         [ 0, 15],\n",
      "         [ 0,  0]],\n",
      "\n",
      "        [[27,  9],\n",
      "         [27,  0],\n",
      "         [ 0, 15],\n",
      "         [ 0,  0]]])\n",
      "\n",
      " shape: torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# 1. używamy gate, żeby stworzyć reprezentację ekspertów zamiast dmodel\n",
    "gate_out = einsum('batch cutoff dmodel, cutoff n_experts -> batch cutoff n_experts', x, gate)\n",
    "print(f'gate_out:\\n{gate_out}\\n\\n shape: {gate_out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[21, 12,  0,  0],\n",
       "         [21, 30,  0,  0],\n",
       "         [27, 27,  0,  0]],\n",
       "\n",
       "        [[ 7,  0, 18,  0],\n",
       "         [ 7,  0, 15,  0],\n",
       "         [ 9,  0, 15,  0]]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wymiar eksperta chcę żeby był na początku\n",
    "gate_out = gate_out.permute(2, 0, 1)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21, 12,  0,  0, 21, 30,  0,  0, 27, 27,  0,  0],\n",
       "        [ 7,  0, 18,  0,  7,  0, 15,  0,  9,  0, 15,  0]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spłaszczam wymiary 2 i 3, żeby każdy ekspert wybrał sobie swobodnie tokeny (ogólnie tokenów w batchu jest 12)\n",
    "gate_out = gate_out.flatten(start_dim=1)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make gate_out float tensor\n",
    "gate_out = gate_out.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teraz przeprowadzamy softmax po 1 wymiarze\n",
    "gate_out = gate_out.softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1221e-04, 1.3848e-08, 8.5083e-14, 8.5083e-14, 1.1221e-04, 9.0924e-01,\n",
       "         8.5083e-14, 8.5083e-14, 4.5268e-02, 4.5268e-02, 8.5083e-14, 8.5083e-14],\n",
       "        [1.5187e-05, 1.3849e-08, 9.0931e-01, 1.3849e-08, 1.5187e-05, 1.3849e-08,\n",
       "         4.5272e-02, 1.3849e-08, 1.1222e-04, 1.3849e-08, 4.5272e-02, 1.3849e-08]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  8,  9,  4,  0,  1, 10],\n",
       "        [ 2, 10,  6,  8,  4,  0,  9]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_gate_out = gate_out\n",
    "# wybierz topk tokenów dla każdego eksperta\n",
    "gate_out = torch.topk(gate_out, k=TOPK, dim=1).indices\n",
    "\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zakoduj wybór eksperta jako one hot\n",
    "# tutaj dodać i odjąć odpowiedni softmax (można jakoś pomnożyć przez one te softmaxy i wtedy dodać i odjąć takie zwierzę)\n",
    "gate_out = torch.nn.functional.one_hot(gate_out, num_classes=12)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate out shape: torch.Size([2, 7, 12]), softmax_gate_out shape: torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "print(f'Gate out shape: {gate_out.shape}, softmax_gate_out shape: {softmax_gate_out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          9.0924e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1221e-04,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.1221e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.3848e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          8.5083e-14, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 9.0931e-01, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          4.5272e-02, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 4.5272e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1222e-04, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5187e-05,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.5187e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3849e-08,\n",
       "          0.0000e+00, 0.0000e+00]]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_mask = einsum('n_experts topk n_examples, n_experts n_examples -> n_experts topk n_examples', gate_out, softmax_gate_out)\n",
    "softmax_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gate out: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 1.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 1.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 1.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          1.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 1.0000, 0.0000, 0.0000]]]) \n",
      "\n",
      " softmax_mask: tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          9.0924e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5268e-02,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1221e-04,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.1221e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 1.3848e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          8.5083e-14, 0.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 9.0931e-01, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          4.5272e-02, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 4.5272e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1222e-04, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5187e-05,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.5187e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3849e-08,\n",
      "          0.0000e+00, 0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "gate_out = gate_out + softmax_mask - softmax_mask\n",
    "print(f'Gate out: {gate_out} \\n\\n softmax_mask: {softmax_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate_out:\n",
      "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])\n",
      "\n",
      " shape: torch.Size([14, 12])\n"
     ]
    }
   ],
   "source": [
    "gate_out_flattened = gate_out.flatten(start_dim=0, end_dim=1)\n",
    "print(f'gate_out:\\n{gate_out_flattened}\\n\\n shape: {gate_out_flattened.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = torch.eye(12)\n",
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_examples:\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "\n",
      " shape: torch.Size([14, 12])\n"
     ]
    }
   ],
   "source": [
    "chosen_examples = einsum('n_elems n_elems, expert_layer_width n_elems -> expert_layer_width n_elems', id, gate_out_flattened)\n",
    "print(f'chosen_examples:\\n{chosen_examples}\\n\\n shape: {chosen_examples.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_chosen_examples = (chosen_examples.sum(dim=0) == 0).float()\n",
    "not_chosen_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 12])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z powrotem odwróć spłaszczenie\n",
    "# gate_out = gate_out.view(2, TOPK, 3, 4)\n",
    "gate_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=3, cutoff=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0, 3, 3],\n",
       "         [3, 2, 3, 0, 1],\n",
       "         [3, 1, 1, 0, 0],\n",
       "         [0, 2, 2, 1, 1]],\n",
       "\n",
       "        [[1, 3, 1, 2, 1],\n",
       "         [1, 1, 1, 3, 0],\n",
       "         [1, 3, 3, 1, 3],\n",
       "         [1, 1, 2, 1, 3]],\n",
       "\n",
       "        [[3, 0, 3, 0, 1],\n",
       "         [0, 1, 1, 0, 3],\n",
       "         [1, 3, 1, 0, 3],\n",
       "         [2, 1, 0, 2, 3]]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 3, 3],\n",
       "        [3, 2, 3, 0, 1],\n",
       "        [3, 1, 1, 0, 0],\n",
       "        [0, 2, 2, 1, 1],\n",
       "        [1, 3, 1, 2, 1],\n",
       "        [1, 1, 1, 3, 0],\n",
       "        [1, 3, 3, 1, 3],\n",
       "        [1, 1, 2, 1, 3],\n",
       "        [3, 0, 3, 0, 1],\n",
       "        [0, 1, 1, 0, 3],\n",
       "        [1, 3, 1, 0, 3],\n",
       "        [2, 1, 0, 2, 3]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.flatten(start_dim=0, end_dim=1)\n",
    "x\n",
    "# tu zapisać x przed wejściem do layera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_before_experts = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[[1, 3, 1, 2, 1],\n",
      "         [0, 1, 0, 3, 3],\n",
      "         [3, 0, 3, 0, 1],\n",
      "         [1, 1, 2, 1, 3],\n",
      "         [2, 1, 0, 2, 3],\n",
      "         [0, 2, 2, 1, 1],\n",
      "         [3, 2, 3, 0, 1]],\n",
      "\n",
      "        [[3, 2, 3, 0, 1],\n",
      "         [1, 1, 1, 3, 0],\n",
      "         [0, 1, 1, 0, 3],\n",
      "         [2, 1, 0, 2, 3],\n",
      "         [1, 1, 2, 1, 3],\n",
      "         [0, 2, 2, 1, 1],\n",
      "         [1, 3, 1, 0, 3]]])\n",
      "\n",
      " shape: torch.Size([2, 7, 5])\n"
     ]
    }
   ],
   "source": [
    "# teraz permutujemy macierz x zgodne z tym one hot\n",
    "x = einsum('n_elems dmodel, n_experts topk n_elems -> n_experts topk dmodel', x, gate_out)\n",
    "print(f'x:\\n{x}\\n\\n shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "tensor([[1, 3, 1, 2, 1],\n",
      "        [0, 1, 0, 3, 3],\n",
      "        [3, 0, 3, 0, 1],\n",
      "        [1, 1, 2, 1, 3],\n",
      "        [2, 1, 0, 2, 3],\n",
      "        [0, 2, 2, 1, 1],\n",
      "        [3, 2, 3, 0, 1],\n",
      "        [3, 2, 3, 0, 1],\n",
      "        [1, 1, 1, 3, 0],\n",
      "        [0, 1, 1, 0, 3],\n",
      "        [2, 1, 0, 2, 3],\n",
      "        [1, 1, 2, 1, 3],\n",
      "        [0, 2, 2, 1, 1],\n",
      "        [1, 3, 1, 0, 3]])\n",
      "\n",
      " shape: torch.Size([14, 5])\n"
     ]
    }
   ],
   "source": [
    "# wypłasczamy wymiar 0 i 1, tak żeby otrzymać macierz wejścia do warstwy ekspertóœ\n",
    "x = x.flatten(start_dim=0, end_dim=1)\n",
    "print(f'x:\\n{x}\\n\\n shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 12])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dodajemy do siebie wyniki dla tych tokenów, które były wybrane przez wielu ekspertów\n",
    "chosen_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[0., 1., 0., 3., 3.],\n",
      "        [6., 4., 6., 0., 2.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 4., 4., 2., 2.],\n",
      "        [1., 3., 1., 2., 1.],\n",
      "        [1., 1., 1., 3., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [2., 2., 4., 2., 6.],\n",
      "        [3., 0., 3., 0., 1.],\n",
      "        [0., 1., 1., 0., 3.],\n",
      "        [1., 3., 1., 0., 3.],\n",
      "        [4., 2., 0., 4., 6.]])\n",
      "\n",
      " shape: torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "summed = einsum('expert_layer_width n_elems, expert_layer_width dmodel -> n_elems dmodel', chosen_examples.float(), x.float())\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [3., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [1., 3., 3., 1., 3.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add examples that were not chosen by any expert\n",
    "einsum('n_elems dmodel, n_elems -> n_elems dmodel', x_before_experts, not_chosen_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[0., 1., 0., 3., 3.],\n",
      "        [6., 4., 6., 0., 2.],\n",
      "        [3., 1., 1., 0., 0.],\n",
      "        [0., 4., 4., 2., 2.],\n",
      "        [1., 3., 1., 2., 1.],\n",
      "        [1., 1., 1., 3., 0.],\n",
      "        [1., 3., 3., 1., 3.],\n",
      "        [2., 2., 4., 2., 6.],\n",
      "        [3., 0., 3., 0., 1.],\n",
      "        [0., 1., 1., 0., 3.],\n",
      "        [1., 3., 1., 0., 3.],\n",
      "        [4., 2., 0., 4., 6.]])\n",
      "\n",
      " shape: torch.Size([12, 5])\n"
     ]
    }
   ],
   "source": [
    "summed += einsum('n_elems dmodel, n_elems -> n_elems dmodel', x_before_experts, not_chosen_examples)\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summed:\n",
      "tensor([[[0., 1., 0., 3., 3.],\n",
      "         [6., 4., 6., 0., 2.],\n",
      "         [3., 1., 1., 0., 0.],\n",
      "         [0., 4., 4., 2., 2.]],\n",
      "\n",
      "        [[1., 3., 1., 2., 1.],\n",
      "         [1., 1., 1., 3., 0.],\n",
      "         [1., 3., 3., 1., 3.],\n",
      "         [2., 2., 4., 2., 6.]],\n",
      "\n",
      "        [[3., 0., 3., 0., 1.],\n",
      "         [0., 1., 1., 0., 3.],\n",
      "         [1., 3., 1., 0., 3.],\n",
      "         [4., 2., 0., 4., 6.]]])\n",
      "\n",
      " shape: torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# again reshape summed to original shape with batch and cutoff\n",
    "summed = summed.view(3, 4, 5)\n",
    "print(f'summed:\\n{summed}\\n\\n shape: {summed.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
